Federated Learning (FL) is fundamentally limited by "client drift," where non-IID data across clients causes local updates to diverge, leading to unstable global convergence and degraded generalization. We explore the use of learned temperature as a local modulator to manage the diverse "signal" and "noise" levels inherent in heterogeneous Federated Learning. By using a lightweight auxiliary head (TempNet) to monitor local training dynamics, we investigate how temperature scaling can modulate the loss landscape to prioritize more stable updates, thus effectively approximating a form of Inverse-Variance Weighting (IVW). Our exploration demonstrates that this adaptive approach helps stabilize the global optimization process and improves generalization across complex scenarios involving both label and feature skew, outperforming standard baselines including FedLeSAM, FedProx, and FedSAM.
